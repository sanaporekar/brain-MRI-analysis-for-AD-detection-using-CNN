{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
        "\n",
        "# Define data directories\n",
        "train_dir = '/content/drive/MyDrive/MCI-CN/MCI-CN/train'\n",
        "test_dir = '/content/drive/MyDrive/MCI-CN/MCI-CN//test'\n",
        "\n",
        "# Parameters\n",
        "input_shape = (32, 32, 3)\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "\n",
        "# Data augmentation for training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# No augmentation for test set\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow images from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(input_shape[0], input_shape[1]),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(input_shape[0], input_shape[1]),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "# Define LeNet model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=input_shape),\n",
        "    tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu'),\n",
        "    tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(120, activation='tanh'),\n",
        "    tf.keras.layers.Dense(84, activation='tanh'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=epochs)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Predict probabilities for test set\n",
        "y_pred_prob = model.predict(test_generator).flatten()\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Predicted classes\n",
        "y_pred = np.where(y_pred_prob > 0.5, 1, 0)\n",
        "\n",
        "# Calculate precision and AUC\n",
        "precision = precision_score(y_true, y_pred)\n",
        "auc = roc_auc_score(y_true, y_pred_prob)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"AUC:\", auc)\n"
      ],
      "metadata": {
        "id": "HC-IlCKS0b5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fa52216-b891-4291-abb2-8326601befee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1072 images belonging to 2 classes.\n",
            "Found 286 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "34/34 [==============================] - 4s 102ms/step - loss: 0.6070 - accuracy: 0.6278\n",
            "Epoch 2/20\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.4621 - accuracy: 0.7687\n",
            "Epoch 3/20\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.4013 - accuracy: 0.8172\n",
            "Epoch 4/20\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 0.3542 - accuracy: 0.8507\n",
            "Epoch 5/20\n",
            "34/34 [==============================] - 3s 102ms/step - loss: 0.3231 - accuracy: 0.8769\n",
            "Epoch 6/20\n",
            "34/34 [==============================] - 3s 102ms/step - loss: 0.3481 - accuracy: 0.8489\n",
            "Epoch 7/20\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.2982 - accuracy: 0.8797\n",
            "Epoch 8/20\n",
            "34/34 [==============================] - 3s 91ms/step - loss: 0.2913 - accuracy: 0.8713\n",
            "Epoch 9/20\n",
            "34/34 [==============================] - 3s 90ms/step - loss: 0.2425 - accuracy: 0.8974\n",
            "Epoch 10/20\n",
            "34/34 [==============================] - 3s 92ms/step - loss: 0.2297 - accuracy: 0.9095\n",
            "Epoch 11/20\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.2360 - accuracy: 0.9076\n",
            "Epoch 12/20\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 0.2125 - accuracy: 0.9123\n",
            "Epoch 13/20\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.2391 - accuracy: 0.9011\n",
            "Epoch 14/20\n",
            "34/34 [==============================] - 3s 92ms/step - loss: 0.1876 - accuracy: 0.9216\n",
            "Epoch 15/20\n",
            "34/34 [==============================] - 3s 91ms/step - loss: 0.2409 - accuracy: 0.8937\n",
            "Epoch 16/20\n",
            "34/34 [==============================] - 3s 89ms/step - loss: 0.1854 - accuracy: 0.9272\n",
            "Epoch 17/20\n",
            "34/34 [==============================] - 4s 104ms/step - loss: 0.1825 - accuracy: 0.9310\n",
            "Epoch 18/20\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.1633 - accuracy: 0.9403\n",
            "Epoch 19/20\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.1537 - accuracy: 0.9403\n",
            "Epoch 20/20\n",
            "34/34 [==============================] - 3s 91ms/step - loss: 0.1411 - accuracy: 0.9440\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.2383 - accuracy: 0.9091\n",
            "Test Loss: 0.23830623924732208\n",
            "Test Accuracy: 0.9090909361839294\n",
            "9/9 [==============================] - 1s 83ms/step\n",
            "Precision: 0.436241610738255\n",
            "AUC: 0.4906728515137912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHpzhAkSRQgQ",
        "outputId": "be18095d-1d90-4531-cba0-f1408c3a1a94"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Nyltpjc2Opq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}